\begin{example}[Continuation of \exaref{exa:hlnAccountingRep}]
    Let us recall the statistic of \exaref{exa:hlnAccountingRep} and consider a dataset of $\datanum=20$ states summarized in the frequency table:
    \begin{center}
        \begin{tabular}{|c|ccc|}
            \hline
            \textbf{Frequency in Dataset} & $\catindexof{A1}$ & $\catindexof{A2}$ & $\catindexof{F}$ \\
            \hline
            0                             & 0                    & 0                    & 0                   \\
            0                             & 0                    & 0                    & 1                   \\
            7                             & 0                    & 1                    & 0                   \\
            2                             & 0                    & 1                    & 1                   \\
            1                             & 1                    & 0                    & 0                   \\
            10                            & 1                    & 0                    & 1                   \\
            0                             & 1                    & 1                    & 0                   \\
            0                             & 1                    & 1                    & 1                   \\
            \hline
        \end{tabular}
    \end{center}
    We then have for the satisfaction rates of $\formulaof{0}=\catvariableof{A1}\oplus\catvariableof{A2}$ and $\formulaof{1}=\catvariableof{F}\Rightarrow\catvariableof{A1}$
    \begin{align*}
        \datameanat{\selvariable=0} = \frac{20}{20} = 1 \andspace
        \datameanat{\selvariable=1} = \frac{7+1+10}{20} = 0.9 \, .
    \end{align*}
    Then \algoref{alg:AMM_HLN} yields with a reasonable convergence criterion choice (such as finite iterations or convergence of $\canparamat{\selvariable}$)
    \begin{align*}
        \hardlegset = \{0\} \quad, \quad \headindexof{\hardlegset} = 1 \andspace
        \canparamat{\selvariable} =
        \begin{bmatrix}
            0 \\
            \lnof{(\frac{0.9}{0.1})\cdot(\frac{1}{3})}
        \end{bmatrix}
        =
        \begin{bmatrix}
            0 \\
            \lnof{3}
        \end{bmatrix}
        \approx
        \begin{bmatrix}
            0 \\
            1.098612
        \end{bmatrix} \, .
    \end{align*}
    To derive this, we notice that \algoref{alg:AMM_HLN} treats formula $\formulaof{0}$ as a hard constraint and assigns $\hardlegset = \{0\}$ and $\headindexof{\hardlegset} = 1$.
    In the $\mathrm{While}$ loop we then have for the formula $\formulaof{1}$
    \begin{align*}
        \hypercoreat{\headvariableof{1}}
        = \contractionof{\bencodingofat{\formulaof{0}}{\headvariableof{0},\catvariableof{F},\catvariableof{A1},\catvariableof{A2}},
            \bencodingofat{\formulaof{1}}{\headvariableof{1},\catvariableof{F},\catvariableof{A1},\catvariableof{A2}}}{\headvariableof{1}}
        = \begin{bmatrix}
              1 \\
              3
        \end{bmatrix}
    \end{align*}
    since $\formulaof{0}$ has $4$ models, of which $3$ are also models of $\formulaof{1}$ and $1$ is instead a model of $\lnot\formulaof{1}$.
    Notice, that the tensor $\hypercoreat{\headvariableof{1}}$ will not change in any further iteration of the $\mathrm{While}$ and the parameter $\canparamat{\selvariable=1}$ will therefore stay constant until the termination of the algorithm.
%    We compare these with the satisfaction rates of $\formulaof{1}$
\end{example}
