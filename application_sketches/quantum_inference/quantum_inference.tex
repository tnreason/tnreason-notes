\documentclass[aps,onecolumn,nofootinbib,pra]{article}

\usepackage{../../article_compilation/spec_files/arxiv}
\input{../../article_compilation/spec_files/standard_preamble.tex}

\input{../../macros/organization_macros.tex}
\input{../../macros/general_macros.tex}
\input{../../macros/tc_macros.tex}
\input{../../macros/tikz_macros.tex}

\begin{document}
    \title{Quantum Inference on \ComputationActivationNetworks{}}

    \maketitle
    \date{\today}
    \begin{abstract}
        We study a quantum rejection sampling scheme to prepare samples from \ComputationActivationNetworks{}.
    \end{abstract}

    \tableofcontents

    \input{./sections/introduction}
    \input{./sections/circuit_representation}
    \input{./sections/encoding_schemes}
    \input{./sections/sampling}
    \input{./sections/implementation}

    \appendix


    \section{Extension: Sampling from proposal distributions}

    We can prepare basis circuit encodings to selection augmented formulas, in this way introducing formula selecting networks.

    \textbf{Idea for an inductive reasoning scheme:} Prepare a q-sample from the empirical distribution and the current distribution.
    Then prepare the basis circuit encodings, where the selection variables are shared and the distributed variables assigned to the prepared samples.
    Now, the ancilla qubits can be designed to $\onehotmapof{1}$ and $\onehotmapof{0}$ accordingly.
    The rejection sampling scheme on both ancillas being $1$ and the measurement of $\selvariable$ prepares then the distribution
    \begin{align*}
        \normalizationof{
            \contractionof{\empdistributionwith, \sencmlnstatwith}{\selvariable}, \contractionof{\currentdistributionwith}{\selvariable}
        }{\selvariable}
    \end{align*}
    That is, the probability of selecting $\selindex$ is proportional to
    \begin{align*}
        \datameanat{\indexedselvariable} \cdot (1-\currentmeanat{\indexedselvariable})
    \end{align*}
    and thus prefers formulas, which have a large empirical mean, but a small current mean.

    \textbf{Open Question:} Since the distribution is "similar" to $\expof{\datameanat{\indexedselvariable}-\currentmeanat{\indexedselvariable})}$ (terms appear in Taylor of first order), can we tune the distribution with an inverse temperature parameter $\beta$?


    \section{Comparing tensor networks and quantum circuits}

    First of all, we need to extend to complex tensors, which are maps
    \begin{align*}
        \hypercore : \atomstates \rightarrow \mathbb{C} \,
    \end{align*}
    with image in $\mathbb{C}$ instead of $\mathbb{R}$ as in the report.

    A coarse comparison of the nomenclature used for quantum circuits and tensor networks:

    \begin{center}
        \begin{tabular}{l|l}
            \textbf{Quantum Circuit} & \textbf{Tensor Network}   \\
            \hline
            Qubit                    & Boolean Variable          \\
            Quantum Gate             & Unitary Tensor            \\
            Quantum Circuit          & Tensor Network on a graph
        \end{tabular}
    \end{center}

    Some constraints appear for a tensor network to be a quantum circuit
    \begin{itemize}
        \item \textbf{Unitarity of each gate:} That is the variables of each tensor are bipartite into sets $\variablesetof{\insymbol}$ and $\variablesetof{\outsymbol}$ of same cardinality and the basis encoding with respect to this bipartition, that is
        \begin{align*}
            T_{\insymbol \rightarrow \outsymbol}[\catvariableof{\insymbol},\catvariableof{\outsymbol}] : \bigotimes_{\atomenumerator\in\variablesetof{\insymbol}} \mathbb{C}^2 \rightarrow \bigotimes_{\atomenumerator\in\variablesetof{\outsymbol}} \mathbb{C}^2  \, ,
        \end{align*}
        is a unitary map, that is
        \begin{align*}
            \left(T_{\insymbol \rightarrow \outsymbol}\right)^H \circ \left(T_{\insymbol \rightarrow \outsymbol}\right)
            = \contractionof{
                T_{\insymbol \rightarrow \outsymbol}[\catvariableof{\insymbol},\seccatvariable],
                \overline{T}_{\insymbol \rightarrow \outsymbol}[\seccatvariable,\catvariableof{\outsymbol}]
            }{\catvariableof{\outsymbol},\catvariableof{\insymbol}}
            = \identityat{\catvariableof{\outsymbol},\catvariableof{\insymbol}}.
        \end{align*}
        \item \textbf{Incoming-Outgoing structure:} Variable appear at most once as incoming and at most once as outgoing variables.
        Those not appearing as outgoing (respectively as incoming) are the input and the output variables of the whole circuit.
        \item \textbf{Acyclicity:} Incoming and outgoing variables of each tensor core provide a direction of each edge tensor. With respect to this directionality the graph underlying the tensor network has to be acyclic.
    \end{itemize}

    The unitary tensors can be aligned layerwise, if and only if the last two assumption hold, i.e. the directed graph is acyclic and each variable appears at most once as an incoming and at most once as an outgoing variable.


    \section{POVM measurements as contractions}

    The main difficulty of using quantum circuits as contraction providers is that we can only extract information through measurements.
    Therefore measurement is the only way to execute contractions of the circuit, which come with restrictions when interested in contraction with open variables.

    The most general measurement formalism is through a POVM, a set $\{E_\seccatindex \, : \, \seccatindex\in[r]\}$ of positive operators with % Nielsen book notation
    \begin{align*}
        \sum_{\seccatindex\in[r]} E_\seccatindex = I
    \end{align*}

    Measuring a pure state $\ket{\psi}$ We then get outcome $m$ with probability
    \begin{align*}
        \braket{\psi|E_\seccatindex|\psi}
    \end{align*}

    We define a measurement variable $\headvariable$ taking indices $\seccatindex\in[r]$ and a measurement tensor
    \begin{align*}
        E[\headvariable,\catvariableof{\insymbol},\catvariableof{\outsymbol}]
    \end{align*}
    with slices
    \begin{align*}
        E[\headvariable=\seccatindex,\catvariableof{\insymbol},\catvariableof{\outsymbol}] = E_\seccatindex \, .
    \end{align*}

    Repeating the measurement asymptotically on a state $\ket{\psi}$ prepared by a quantum circuit $\tnetof{\graph}$ acting on the trivial start state $\ones$, we denote the measurement outcome by $\seccatindex^\datindex$.
    In the limit $\datanum\rightarrow\infty$ we get almost surely
%    we thus get the contraction
    \begin{align*}
        \frac{1}{\datanum} \sum_{\datindexin} \onehotmapofat{\seccatindex^\datindex}{\headvariable} \rightarrow
        \contractionof{\tnetof{\graph}[\catvariableof{\insymbol}],E[\headvariable,\catvariableof{\insymbol},\catvariableof{\outsymbol}],\tnetof{\secgraph}[\catvariableof{\outsymbol}]}{\headvariable} \, .
    \end{align*}

    % Case of computational basis measurements
    POVMs to computational basis measurements of subsets of qubits are constructed as products with delta tensors on the non-measured qubits.


    \section{Alternative Contraction Provider: Overlap-measuring Circuits}

    Quantum Circuits such as the SWAP test and the Hadamard test can be used to measure overlaps of quantum states, which are the squared absolutes of contractions of two state tensors.
    \begin{itemize}
        \item When we have preparation schemes for two tensors, we can control them with a common ancilla qubit and measure their contraction by a Hadamard test (alternatively, using the SWAP test and state preparation in two registers).
        \item Can we extend these schemes to contractions of more general tensor networks?
    \end{itemize}

    \bibliographystyle{plainnat}
    \bibliography{../../references.bib}


\end{document}