\section{Mean as a Statistic}

We in this section take the perspective of estimating a maximum entropy distribution given observed data.
\begin{itemize}
    \item $\datamean$ is an unbiased estimator of $\meanparam$, i.e. $\expectationof{\datameanat{\selvariable}}=\meanparam$
    \item $\datamean$ is a consistent estimator of $\meanparam$, i.e. $\datameanat{\selvariable}\rightarrow\meanparam$ by the law of large numbers coordinatewise almost everywhere.
    \item $\datamean$ is the minimal variance unbiased estimator of $\meanparam$. %CHECK
\end{itemize}


The mean parameter $\datamean$ given a dataset can be understood as a statistic of the dataset.
We here show that for the family of maximum entropy distributions this statistic is a minimal sufficient statistic.

The family of maximum entropy distributions is the set
\begin{align*}
    \left\{ \probofat{\meanparam}{\shortcatvariables} \wcols \meanparam\in\meansetof{\sstat,\basemeasure}\right\}
\end{align*}
which has been characterized above by a union of exponential families with respect to face measures.

Taking a frequentist perspective we now understand datasets by random variables $\catvariableof{[\catorder]\times[\datanum]}$, where for $\datindexin$ the variables $\catvariableof{[\catorder],\datindex}$ are drawn i.i.d. from a maximum entropy distribution.
The mean statistic is then a tensor
\begin{align*}
    \datameanat{\catvariableof{[\catorder]\times[\datanum]},\selvariable}
\end{align*}
whith coordinates
\begin{align*}
    \datameanat{\indexedcatvariableof{[\catorder]\times[\datanum]},\selvariable}
    = \frac{1}{\datanum}\sum_{\datindexin} \sencodingofat{\sstat}{\indexedcatvariableof{[\catorder],\datindex},\selvariable} \, .
\end{align*}


\begin{theorem}
    The mean statistic is a sufficient statistic for the family of maximum entropy distributions $(\sstat,\basemeasure)$.
    If the base measure has maximal support, the mean statistic is in addition minimal.
\end{theorem}
\begin{proof}
    It sufficies to show that the likelihood is a function of $\datamean$.
    Let us choose a face $\facecondset$ of $\genmeanset$, then the likelihood is different from $0$ if and only if the empirical distribution is representable with respect to the face measure.
    This is the case if and only if $\datamean$ is on the face.
    In case that $\datamean$ is on the face, then the likelihood of any distribution on that face exponential family is
    \begin{align*}
        \expof{\datanum\cdot \left(\contraction{\datameanat{\catvariableof{[\catorder]\times[\datanum]},\selvariable},\canparamwith} - \cumfunctionof{\canparam}\right)}
    \end{align*}
    We have thus shown that the likelihood is always a function of $\datamean$.

    The minimality claim can be shown by the constant quotient criterion (see Thm. 6.2.13 in \cite{casella_statistical_2001}).
\end{proof}