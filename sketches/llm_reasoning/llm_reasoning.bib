
@misc{xiang_towards_2025,
	title = {Towards {System} 2 {Reasoning} in {LLMs}: {Learning} {How} to {Think} {With} {Meta} {Chain}-of-{Thought}},
	shorttitle = {Towards {System} 2 {Reasoning} in {LLMs}},
	url = {http://arxiv.org/abs/2501.04682},
	doi = {10.48550/arXiv.2501.04682},
	abstract = {We propose a novel framework, Meta Chain-of-Thought (Meta-CoT), which extends traditional Chain-of-Thought (CoT) by explicitly modeling the underlying reasoning required to arrive at a particular CoT. We present empirical evidence from state-of-the-art models exhibiting behaviors consistent with in-context search, and explore methods for producing Meta-CoT via process supervision, synthetic data generation, and search algorithms. Finally, we outline a concrete pipeline for training a model to produce Meta-CoTs, incorporating instruction tuning with linearized search traces and reinforcement learning post-training. Finally, we discuss open research questions, including scaling laws, verifier roles, and the potential for discovering novel reasoning algorithms. This work provides a theoretical and practical roadmap to enable Meta-CoT in LLMs, paving the way for more powerful and human-like reasoning in artificial intelligence.},
	urldate = {2025-02-06},
	publisher = {arXiv},
	author = {Xiang, Violet and Snell, Charlie and Gandhi, Kanishk and Albalak, Alon and Singh, Anikait and Blagden, Chase and Phung, Duy and Rafailov, Rafael and Lile, Nathan and Mahan, Dakota and Castricato, Louis and Franken, Jan-Philipp and Haber, Nick and Finn, Chelsea},
	month = jan,
	year = {2025},
	note = {arXiv:2501.04682 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	file = {Preprint PDF:/Users/alexgoessmann/Zotero/storage/EY45G6EW/Xiang et al. - 2025 - Towards System 2 Reasoning in LLMs Learning How to Think With Meta Chain-of-Thought.pdf:application/pdf;Snapshot:/Users/alexgoessmann/Zotero/storage/XJ79CQ9J/2501.html:text/html},
}

@misc{guan_rstar-math_2025,
	title = {{rStar}-{Math}: {Small} {LLMs} {Can} {Master} {Math} {Reasoning} with {Self}-{Evolved} {Deep} {Thinking}},
	shorttitle = {{rStar}-{Math}},
	url = {http://arxiv.org/abs/2501.04519},
	doi = {10.48550/arXiv.2501.04519},
	abstract = {We present rStar-Math to demonstrate that small language models (SLMs) can rival or even surpass the math reasoning capability of OpenAI o1, without distillation from superior models. rStar-Math achieves this by exercising "deep thinking" through Monte Carlo Tree Search (MCTS), where a math policy SLM performs test-time search guided by an SLM-based process reward model. rStar-Math introduces three innovations to tackle the challenges in training the two SLMs: (1) a novel code-augmented CoT data sythesis method, which performs extensive MCTS rollouts to generate step-by-step verified reasoning trajectories used to train the policy SLM; (2) a novel process reward model training method that avoids na{\textbackslash}"ive step-level score annotation, yielding a more effective process preference model (PPM); (3) a self-evolution recipe in which the policy SLM and PPM are built from scratch and iteratively evolved to improve reasoning capabilities. Through 4 rounds of self-evolution with millions of synthesized solutions for 747k math problems, rStar-Math boosts SLMs' math reasoning to state-of-the-art levels. On the MATH benchmark, it improves Qwen2.5-Math-7B from 58.8\% to 90.0\% and Phi3-mini-3.8B from 41.4\% to 86.4\%, surpassing o1-preview by +4.5\% and +0.9\%. On the USA Math Olympiad (AIME), rStar-Math solves an average of 53.3\% (8/15) of problems, ranking among the top 20\% the brightest high school math students. Code and data will be available at https://github.com/microsoft/rStar.},
	urldate = {2025-02-06},
	publisher = {arXiv},
	author = {Guan, Xinyu and Zhang, Li Lyna and Liu, Yifei and Shang, Ning and Sun, Youran and Zhu, Yi and Yang, Fan and Yang, Mao},
	month = jan,
	year = {2025},
	note = {arXiv:2501.04519 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Preprint PDF:/Users/alexgoessmann/Zotero/storage/7BKMCEVL/Guan et al. - 2025 - rStar-Math Small LLMs Can Master Math Reasoning with Self-Evolved Deep Thinking.pdf:application/pdf;Snapshot:/Users/alexgoessmann/Zotero/storage/YJUDLWSL/2501.html:text/html},
}

@misc{deepseek-ai_deepseek-r1_2025,
	title = {{DeepSeek}-{R1}: {Incentivizing} {Reasoning} {Capability} in {LLMs} via {Reinforcement} {Learning}},
	shorttitle = {{DeepSeek}-{R1}},
	url = {http://arxiv.org/abs/2501.12948},
	doi = {10.48550/arXiv.2501.12948},
	abstract = {We introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1. DeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without supervised fine-tuning (SFT) as a preliminary step, demonstrates remarkable reasoning capabilities. Through RL, DeepSeek-R1-Zero naturally emerges with numerous powerful and intriguing reasoning behaviors. However, it encounters challenges such as poor readability, and language mixing. To address these issues and further enhance reasoning performance, we introduce DeepSeek-R1, which incorporates multi-stage training and cold-start data before RL. DeepSeek-R1 achieves performance comparable to OpenAI-o1-1217 on reasoning tasks. To support the research community, we open-source DeepSeek-R1-Zero, DeepSeek-R1, and six dense models (1.5B, 7B, 8B, 14B, 32B, 70B) distilled from DeepSeek-R1 based on Qwen and Llama.},
	urldate = {2025-02-06},
	publisher = {arXiv},
	author = {DeepSeek-AI and Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and Zhang, Xiaokang and Yu, Xingkai and Wu, Yu and Wu, Z. F. and Gou, Zhibin and Shao, Zhihong and Li, Zhuoshu and Gao, Ziyi and Liu, Aixin and Xue, Bing and Wang, Bingxuan and Wu, Bochao and Feng, Bei and Lu, Chengda and Zhao, Chenggang and Deng, Chengqi and Zhang, Chenyu and Ruan, Chong and Dai, Damai and Chen, Deli and Ji, Dongjie and Li, Erhang and Lin, Fangyun and Dai, Fucong and Luo, Fuli and Hao, Guangbo and Chen, Guanting and Li, Guowei and Zhang, H. and Bao, Han and Xu, Hanwei and Wang, Haocheng and Ding, Honghui and Xin, Huajian and Gao, Huazuo and Qu, Hui and Li, Hui and Guo, Jianzhong and Li, Jiashi and Wang, Jiawei and Chen, Jingchang and Yuan, Jingyang and Qiu, Junjie and Li, Junlong and Cai, J. L. and Ni, Jiaqi and Liang, Jian and Chen, Jin and Dong, Kai and Hu, Kai and Gao, Kaige and Guan, Kang and Huang, Kexin and Yu, Kuai and Wang, Lean and Zhang, Lecong and Zhao, Liang and Wang, Litong and Zhang, Liyue and Xu, Lei and Xia, Leyi and Zhang, Mingchuan and Zhang, Minghua and Tang, Minghui and Li, Meng and Wang, Miaojun and Li, Mingming and Tian, Ning and Huang, Panpan and Zhang, Peng and Wang, Qiancheng and Chen, Qinyu and Du, Qiushi and Ge, Ruiqi and Zhang, Ruisong and Pan, Ruizhe and Wang, Runji and Chen, R. J. and Jin, R. L. and Chen, Ruyi and Lu, Shanghao and Zhou, Shangyan and Chen, Shanhuang and Ye, Shengfeng and Wang, Shiyu and Yu, Shuiping and Zhou, Shunfeng and Pan, Shuting and Li, S. S. and Zhou, Shuang and Wu, Shaoqing and Ye, Shengfeng and Yun, Tao and Pei, Tian and Sun, Tianyu and Wang, T. and Zeng, Wangding and Zhao, Wanjia and Liu, Wen and Liang, Wenfeng and Gao, Wenjun and Yu, Wenqin and Zhang, Wentao and Xiao, W. L. and An, Wei and Liu, Xiaodong and Wang, Xiaohan and Chen, Xiaokang and Nie, Xiaotao and Cheng, Xin and Liu, Xin and Xie, Xin and Liu, Xingchao and Yang, Xinyu and Li, Xinyuan and Su, Xuecheng and Lin, Xuheng and Li, X. Q. and Jin, Xiangyue and Shen, Xiaojin and Chen, Xiaosha and Sun, Xiaowen and Wang, Xiaoxiang and Song, Xinnan and Zhou, Xinyi and Wang, Xianzu and Shan, Xinxia and Li, Y. K. and Wang, Y. Q. and Wei, Y. X. and Zhang, Yang and Xu, Yanhong and Li, Yao and Zhao, Yao and Sun, Yaofeng and Wang, Yaohui and Yu, Yi and Zhang, Yichao and Shi, Yifan and Xiong, Yiliang and He, Ying and Piao, Yishi and Wang, Yisong and Tan, Yixuan and Ma, Yiyang and Liu, Yiyuan and Guo, Yongqiang and Ou, Yuan and Wang, Yuduan and Gong, Yue and Zou, Yuheng and He, Yujia and Xiong, Yunfan and Luo, Yuxiang and You, Yuxiang and Liu, Yuxuan and Zhou, Yuyang and Zhu, Y. X. and Xu, Yanhong and Huang, Yanping and Li, Yaohui and Zheng, Yi and Zhu, Yuchen and Ma, Yunxian and Tang, Ying and Zha, Yukun and Yan, Yuting and Ren, Z. Z. and Ren, Zehui and Sha, Zhangli and Fu, Zhe and Xu, Zhean and Xie, Zhenda and Zhang, Zhengyan and Hao, Zhewen and Ma, Zhicheng and Yan, Zhigang and Wu, Zhiyu and Gu, Zihui and Zhu, Zijia and Liu, Zijun and Li, Zilin and Xie, Ziwei and Song, Ziyang and Pan, Zizheng and Huang, Zhen and Xu, Zhipeng and Zhang, Zhongyu and Zhang, Zhen},
	month = jan,
	year = {2025},
	note = {arXiv:2501.12948 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	file = {Preprint PDF:/Users/alexgoessmann/Zotero/storage/KKDAM7V2/DeepSeek-AI et al. - 2025 - DeepSeek-R1 Incentivizing Reasoning Capability in LLMs via Reinforcement Learning.pdf:application/pdf;Snapshot:/Users/alexgoessmann/Zotero/storage/NGMHSCGQ/2501.html:text/html},
}

@misc{park_ensembling_2024,
	title = {Ensembling {Large} {Language} {Models} with {Process} {Reward}-{Guided} {Tree} {Search} for {Better} {Complex} {Reasoning}},
	url = {http://arxiv.org/abs/2412.15797},
	doi = {10.48550/arXiv.2412.15797},
	abstract = {Despite recent advances in large language models, open-source models often struggle to consistently perform well on complex reasoning tasks. Existing ensemble methods, whether applied at the token or output levels, fail to address these challenges. In response, we present Language model Ensemble with Monte Carlo Tree Search (LE-MCTS), a novel framework for process-level ensembling of language models. LE-MCTS formulates step-by-step reasoning with an ensemble of language models as a Markov decision process. In this framework, states represent intermediate reasoning paths, while actions consist of generating the next reasoning step using one of the language models selected from a predefined pool. Guided by a process-based reward model, LE-MCTS performs a tree search over the reasoning steps generated by different language models, identifying the most accurate reasoning chain. Experimental results on five mathematical reasoning benchmarks demonstrate that our approach outperforms both single language model decoding algorithms and language model ensemble methods. Notably, LE-MCTS improves performance by 3.6\% and 4.3\% on the MATH and MQA datasets, respectively, highlighting its effectiveness in solving complex reasoning problems.},
	urldate = {2025-02-06},
	publisher = {arXiv},
	author = {Park, Sungjin and Liu, Xiao and Gong, Yeyun and Choi, Edward},
	month = dec,
	year = {2024},
	note = {arXiv:2412.15797 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Preprint PDF:/Users/alexgoessmann/Zotero/storage/INZLUS5A/Park et al. - 2024 - Ensembling Large Language Models with Process Reward-Guided Tree Search for Better Complex Reasoning.pdf:application/pdf;Snapshot:/Users/alexgoessmann/Zotero/storage/I3IKYV24/2412.html:text/html},
}

@article{rudolph_synergy_2023,
	title = {Synergy {Between} {Quantum} {Circuits} and {Tensor} {Networks}: {Short}-cutting the {Race} to {Practical} {Quantum} {Advantage}},
	volume = {14},
	issn = {2041-1723},
	shorttitle = {Synergy {Between} {Quantum} {Circuits} and {Tensor} {Networks}},
	url = {http://arxiv.org/abs/2208.13673},
	doi = {10.1038/s41467-023-43908-6},
	abstract = {While recent breakthroughs have proven the ability of noisy intermediate-scale quantum (NISQ) devices to achieve quantum advantage in classically-intractable sampling tasks, the use of these devices for solving more practically relevant computational problems remains a challenge. Proposals for attaining practical quantum advantage typically involve parametrized quantum circuits (PQCs), whose parameters can be optimized to find solutions to diverse problems throughout quantum simulation and machine learning. However, training PQCs for real-world problems remains a significant practical challenge, largely due to the phenomenon of barren plateaus in the optimization landscapes of randomly-initialized quantum circuits. In this work, we introduce a scalable procedure for harnessing classical computing resources to provide pre-optimized initializations for PQCs, which we show significantly improves the trainability and performance of PQCs on a variety of problems. Given a specific optimization task, this method first utilizes tensor network (TN) simulations to identify a promising quantum state, which is then converted into gate parameters of a PQC by means of a high-performance decomposition procedure. We show that this learned initialization avoids barren plateaus, and effectively translates increases in classical resources to enhanced performance and speed in training quantum circuits. By demonstrating a means of boosting limited quantum resources using classical computers, our approach illustrates the promise of this synergy between quantum and quantum-inspired models in quantum computing, and opens up new avenues to harness the power of modern quantum hardware for realizing practical quantum advantage.},
	number = {1},
	urldate = {2025-02-10},
	journal = {Nature Communications},
	author = {Rudolph, Manuel S. and Miller, Jacob and Motlagh, Danial and Chen, Jing and Acharya, Atithi and Perdomo-Ortiz, Alejandro},
	month = dec,
	year = {2023},
	note = {arXiv:2208.13673 [quant-ph]},
	keywords = {Quantum Physics},
	pages = {8367},
	file = {Preprint PDF:/Users/alexgoessmann/Zotero/storage/KJAPE6WJ/Rudolph et al. - 2023 - Synergy Between Quantum Circuits and Tensor Networks Short-cutting the Race to Practical Quantum Ad.pdf:application/pdf;Snapshot:/Users/alexgoessmann/Zotero/storage/GDDUAEAJ/2208.html:text/html},
}

@misc{sander_large-scale_2025,
	title = {Large-scale stochastic simulation of open quantum systems},
	url = {http://arxiv.org/abs/2501.17913},
	doi = {10.48550/arXiv.2501.17913},
	abstract = {Understanding the precise interaction mechanisms between quantum systems and their environment is crucial for advancing stable quantum technologies, designing reliable experimental frameworks, and building accurate models of real-world phenomena. However, simulating open quantum systems, which feature complex non-unitary dynamics, poses significant computational challenges that require innovative methods to overcome. In this work, we introduce the tensor jump method (TJM), a scalable, embarrassingly parallel algorithm for stochastically simulating large-scale open quantum systems, specifically Markovian dynamics captured by Lindbladians. This method is built on three core principles where, in particular, we extend the Monte Carlo wave function (MCWF) method to matrix product states, use a dynamic time-dependent variational principle (TDVP) to significantly reduce errors during time evolution, and introduce what we call a sampling MPS to drastically reduce the dependence on the simulation's time step size. We demonstrate that this method scales more effectively than previous methods and ensures convergence to the Lindbladian solution independent of system size, which we show both rigorously and numerically. Finally, we provide evidence of its utility by simulating Lindbladian dynamics of XXX Heisenberg models up to a thousand spins using a consumer-grade CPU. This work represents a significant step forward in the simulation of large-scale open quantum systems, with the potential to enable discoveries across various domains of quantum physics, particularly those where the environment plays a fundamental role, and to both dequantize and facilitate the development of more stable quantum hardware.},
	urldate = {2025-02-10},
	publisher = {arXiv},
	author = {Sander, Aaron and Fröhlich, Maximilian and Eigel, Martin and Eisert, Jens and Gelß, Patrick and Hintermüller, Michael and Milbradt, Richard M. and Wille, Robert and Mendl, Christian B.},
	month = jan,
	year = {2025},
	note = {arXiv:2501.17913 [quant-ph]},
	keywords = {Quantum Physics, Condensed Matter - Other Condensed Matter},
	file = {Preprint PDF:/Users/alexgoessmann/Zotero/storage/IESQY7GH/Sander et al. - 2025 - Large-scale stochastic simulation of open quantum systems.pdf:application/pdf;Snapshot:/Users/alexgoessmann/Zotero/storage/R5SKJKN7/2501.html:text/html},
}

@misc{yang_formal_2024,
	title = {Formal {Mathematical} {Reasoning}: {A} {New} {Frontier} in {AI}},
	shorttitle = {Formal {Mathematical} {Reasoning}},
	url = {http://arxiv.org/abs/2412.16075},
	doi = {10.48550/arXiv.2412.16075},
	abstract = {AI for Mathematics (AI4Math) is not only intriguing intellectually but also crucial for AI-driven discovery in science, engineering, and beyond. Extensive efforts on AI4Math have mirrored techniques in NLP, in particular, training large language models on carefully curated math datasets in text form. As a complementary yet less explored avenue, formal mathematical reasoning is grounded in formal systems such as proof assistants, which can verify the correctness of reasoning and provide automatic feedback. In this position paper, we advocate for formal mathematical reasoning and argue that it is indispensable for advancing AI4Math to the next level. In recent years, we have seen steady progress in using AI to perform formal reasoning, including core tasks such as theorem proving and autoformalization, as well as emerging applications such as verifiable generation of code and hardware designs. However, significant challenges remain to be solved for AI to truly master mathematics and achieve broader impact. We summarize existing progress, discuss open challenges, and envision critical milestones to measure future success. At this inflection point for formal mathematical reasoning, we call on the research community to come together to drive transformative advancements in this field.},
	urldate = {2025-02-13},
	publisher = {arXiv},
	author = {Yang, Kaiyu and Poesia, Gabriel and He, Jingxuan and Li, Wenda and Lauter, Kristin and Chaudhuri, Swarat and Song, Dawn},
	month = dec,
	year = {2024},
	note = {arXiv:2412.16075 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Logic in Computer Science, Computer Science - Machine Learning},
	file = {Preprint PDF:/Users/alexgoessmann/Zotero/storage/SVBMJKPX/Yang et al. - 2024 - Formal Mathematical Reasoning A New Frontier in AI.pdf:application/pdf;Snapshot:/Users/alexgoessmann/Zotero/storage/X4BBBAS8/2412.html:text/html},
}

@misc{xin_deepseek-prover-v15_2024,
	title = {{DeepSeek}-{Prover}-{V1}.5: {Harnessing} {Proof} {Assistant} {Feedback} for {Reinforcement} {Learning} and {Monte}-{Carlo} {Tree} {Search}},
	shorttitle = {{DeepSeek}-{Prover}-{V1}.5},
	url = {http://arxiv.org/abs/2408.08152},
	doi = {10.48550/arXiv.2408.08152},
	abstract = {We introduce DeepSeek-Prover-V1.5, an open-source language model designed for theorem proving in Lean 4, which enhances DeepSeek-Prover-V1 by optimizing both training and inference processes. Pre-trained on DeepSeekMath-Base with specialization in formal mathematical languages, the model undergoes supervised fine-tuning using an enhanced formal theorem proving dataset derived from DeepSeek-Prover-V1. Further refinement is achieved through reinforcement learning from proof assistant feedback (RLPAF). Beyond the single-pass whole-proof generation approach of DeepSeek-Prover-V1, we propose RMaxTS, a variant of Monte-Carlo tree search that employs an intrinsic-reward-driven exploration strategy to generate diverse proof paths. DeepSeek-Prover-V1.5 demonstrates significant improvements over DeepSeek-Prover-V1, achieving new state-of-the-art results on the test set of the high school level miniF2F benchmark (\$63.5{\textbackslash}\%\$) and the undergraduate level ProofNet benchmark (\$25.3{\textbackslash}\%\$).},
	urldate = {2025-02-13},
	publisher = {arXiv},
	author = {Xin, Huajian and Ren, Z. Z. and Song, Junxiao and Shao, Zhihong and Zhao, Wanjia and Wang, Haocheng and Liu, Bo and Zhang, Liyue and Lu, Xuan and Du, Qiushi and Gao, Wenjun and Zhu, Qihao and Yang, Dejian and Gou, Zhibin and Wu, Z. F. and Luo, Fuli and Ruan, Chong},
	month = aug,
	year = {2024},
	note = {arXiv:2408.08152 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Logic in Computer Science, Computer Science - Machine Learning},
	file = {Preprint PDF:/Users/alexgoessmann/Zotero/storage/65C8VPFN/Xin et al. - 2024 - DeepSeek-Prover-V1.5 Harnessing Proof Assistant Feedback for Reinforcement Learning and Monte-Carlo.pdf:application/pdf;Snapshot:/Users/alexgoessmann/Zotero/storage/P4M7DBYW/2408.html:text/html},
}

@misc{liu_symagent_2025,
	title = {{SymAgent}: {A} {Neural}-{Symbolic} {Self}-{Learning} {Agent} {Framework} for {Complex} {Reasoning} over {Knowledge} {Graphs}},
	shorttitle = {{SymAgent}},
	url = {http://arxiv.org/abs/2502.03283},
	doi = {10.48550/arXiv.2502.03283},
	abstract = {Recent advancements have highlighted that Large Language Models (LLMs) are prone to hallucinations when solving complex reasoning problems, leading to erroneous results. To tackle this issue, researchers incorporate Knowledge Graphs (KGs) to improve the reasoning ability of LLMs. However, existing methods face two limitations: 1) they typically assume that all answers to the questions are contained in KGs, neglecting the incompleteness issue of KGs, and 2) they treat the KG as a static repository and overlook the implicit logical reasoning structures inherent in KGs. In this paper, we introduce SymAgent, an innovative neural-symbolic agent framework that achieves collaborative augmentation between KGs and LLMs. We conceptualize KGs as dynamic environments and transform complex reasoning tasks into a multi-step interactive process, enabling KGs to participate deeply in the reasoning process. SymAgent consists of two modules: Agent-Planner and Agent-Executor. The Agent-Planner leverages LLM's inductive reasoning capability to extract symbolic rules from KGs, guiding efficient question decomposition. The Agent-Executor autonomously invokes predefined action tools to integrate information from KGs and external documents, addressing the issues of KG incompleteness. Furthermore, we design a self-learning framework comprising online exploration and offline iterative policy updating phases, enabling the agent to automatically synthesize reasoning trajectories and improve performance. Experimental results demonstrate that SymAgent with weak LLM backbones (i.e., 7B series) yields better or comparable performance compared to various strong baselines. Further analysis reveals that our agent can identify missing triples, facilitating automatic KG updates.},
	urldate = {2025-02-13},
	publisher = {arXiv},
	author = {Liu, Ben and Zhang, Jihai and Lin, Fangquan and Yang, Cheng and Peng, Min and Yin, Wotao},
	month = feb,
	year = {2025},
	note = {arXiv:2502.03283 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {Preprint PDF:/Users/alexgoessmann/Zotero/storage/LW3UVMTR/Liu et al. - 2025 - SymAgent A Neural-Symbolic Self-Learning Agent Framework for Complex Reasoning over Knowledge Graph.pdf:application/pdf;Snapshot:/Users/alexgoessmann/Zotero/storage/5JVD57TZ/2502.html:text/html},
}

@misc{lin_zebralogic_2025,
	title = {{ZebraLogic}: {On} the {Scaling} {Limits} of {LLMs} for {Logical} {Reasoning}},
	shorttitle = {{ZebraLogic}},
	url = {http://arxiv.org/abs/2502.01100},
	doi = {10.48550/arXiv.2502.01100},
	abstract = {We investigate the logical reasoning capabilities of large language models (LLMs) and their scalability in complex non-monotonic reasoning. To this end, we introduce ZebraLogic, a comprehensive evaluation framework for assessing LLM reasoning performance on logic grid puzzles derived from constraint satisfaction problems (CSPs). ZebraLogic enables the generation of puzzles with controllable and quantifiable complexity, facilitating a systematic study of the scaling limits of models such as Llama, o1 models, and DeepSeek-R1. By encompassing a broad range of search space complexities and diverse logical constraints, ZebraLogic provides a structured environment to evaluate reasoning under increasing difficulty. Our results reveal a significant decline in accuracy as problem complexity grows -- a phenomenon we term the curse of complexity. This limitation persists even with larger models and increased inference-time computation, suggesting inherent constraints in current LLM reasoning capabilities. Additionally, we explore strategies to enhance logical reasoning, including Best-of-N sampling, backtracking mechanisms, and self-verification prompts. Our findings offer critical insights into the scalability of LLM reasoning, highlight fundamental limitations, and outline potential directions for improvement.},
	urldate = {2025-02-13},
	publisher = {arXiv},
	author = {Lin, Bill Yuchen and Bras, Ronan Le and Richardson, Kyle and Sabharwal, Ashish and Poovendran, Radha and Clark, Peter and Choi, Yejin},
	month = feb,
	year = {2025},
	note = {arXiv:2502.01100 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {Preprint PDF:/Users/alexgoessmann/Zotero/storage/3QX53PZG/Lin et al. - 2025 - ZebraLogic On the Scaling Limits of LLMs for Logical Reasoning.pdf:application/pdf;Snapshot:/Users/alexgoessmann/Zotero/storage/TDV7KSV8/2502.html:text/html},
}

@misc{ye_limo_2025,
	title = {{LIMO}: {Less} is {More} for {Reasoning}},
	shorttitle = {{LIMO}},
	url = {http://arxiv.org/abs/2502.03387},
	doi = {10.48550/arXiv.2502.03387},
	abstract = {We present a fundamental discovery that challenges our understanding of how complex reasoning emerges in large language models. While conventional wisdom suggests that sophisticated reasoning tasks demand extensive training data ({\textgreater}100,000 examples), we demonstrate that complex mathematical reasoning abilities can be effectively elicited with surprisingly few examples. Through comprehensive experiments, our proposed model LIMO demonstrates unprecedented performance in mathematical reasoning. With merely 817 curated training samples, LIMO achieves 57.1\% accuracy on AIME and 94.8\% on MATH, improving from previous SFT-based models' 6.5\% and 59.2\% respectively, while only using 1\% of the training data required by previous approaches. LIMO demonstrates exceptional out-of-distribution generalization, achieving 40.5\% absolute improvement across 10 diverse benchmarks, outperforming models trained on 100x more data, challenging the notion that SFT leads to memorization rather than generalization. Based on these results, we propose the Less-Is-More Reasoning Hypothesis (LIMO Hypothesis): In foundation models where domain knowledge has been comprehensively encoded during pre-training, sophisticated reasoning capabilities can emerge through minimal but precisely orchestrated demonstrations of cognitive processes. This hypothesis posits that the elicitation threshold for complex reasoning is determined by two key factors: (1) the completeness of the model's encoded knowledge foundation during pre-training, and (2) the effectiveness of post-training examples as "cognitive templates" that show the model how to utilize its knowledge base to solve complex reasoning tasks. To facilitate reproducibility and future research in data-efficient reasoning, we release LIMO as a comprehensive open-source suite at https://github.com/GAIR-NLP/LIMO.},
	urldate = {2025-02-13},
	publisher = {arXiv},
	author = {Ye, Yixin and Huang, Zhen and Xiao, Yang and Chern, Ethan and Xia, Shijie and Liu, Pengfei},
	month = feb,
	year = {2025},
	note = {arXiv:2502.03387 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	file = {Preprint PDF:/Users/alexgoessmann/Zotero/storage/M74RYFEA/Ye et al. - 2025 - LIMO Less is More for Reasoning.pdf:application/pdf;Snapshot:/Users/alexgoessmann/Zotero/storage/SG9U47MT/2502.html:text/html},
}

@misc{besta_reasoning_2025,
	title = {Reasoning {Language} {Models}: {A} {Blueprint}},
	shorttitle = {Reasoning {Language} {Models}},
	url = {http://arxiv.org/abs/2501.11223},
	doi = {10.48550/arXiv.2501.11223},
	abstract = {Reasoning language models (RLMs), also known as Large Reasoning Models (LRMs), such as OpenAI's o1 and o3, DeepSeek-V3, and Alibaba's QwQ, have redefined AI's problem-solving capabilities by extending LLMs with advanced reasoning mechanisms. Yet, their high costs, proprietary nature, and complex architectures - uniquely combining Reinforcement Learning (RL), search heuristics, and LLMs - present accessibility and scalability challenges. To address these, we propose a comprehensive blueprint that organizes RLM components into a modular framework, based on a survey and analysis of all RLM works. This blueprint incorporates diverse reasoning structures (chains, trees, graphs, and nested forms), reasoning strategies (e.g., Monte Carlo Tree Search, Beam Search), RL concepts (policy, value models and others), supervision schemes (Outcome-Based and Process-Based Supervision), and other related concepts (e.g., Test-Time Compute, Retrieval-Augmented Generation, agent tools). We also provide detailed mathematical formulations and algorithmic specifications to simplify RLM implementation. By showing how schemes like LLaMA-Berry, QwQ, Journey Learning, and Graph of Thoughts fit as special cases, we demonstrate the blueprint's versatility and unifying potential. To illustrate its utility, we introduce x1, a modular implementation for rapid RLM prototyping and experimentation. Using x1 and a literature review, we provide key insights, such as multi-phase training for policy and value models, and the importance of familiar training distributions. Finally, we discuss scalable RLM cloud deployments and we outline how RLMs can integrate with a broader LLM ecosystem. Our work demystifies RLM construction, democratizes advanced reasoning capabilities, and fosters innovation, aiming to mitigate the gap between "rich AI" and "poor AI" by lowering barriers to RLM design and experimentation.},
	urldate = {2025-02-13},
	publisher = {arXiv},
	author = {Besta, Maciej and Barth, Julia and Schreiber, Eric and Kubicek, Ales and Catarino, Afonso and Gerstenberger, Robert and Nyczyk, Piotr and Iff, Patrick and Li, Yueling and Houliston, Sam and Sternal, Tomasz and Copik, Marcin and Kwaśniewski, Grzegorz and Müller, Jürgen and Flis, Łukasz and Eberhard, Hannes and Niewiadomski, Hubert and Hoefler, Torsten},
	month = jan,
	year = {2025},
	note = {arXiv:2501.11223 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	file = {Preprint PDF:/Users/alexgoessmann/Zotero/storage/2BV4Q2N8/Besta et al. - 2025 - Reasoning Language Models A Blueprint.pdf:application/pdf;Snapshot:/Users/alexgoessmann/Zotero/storage/M6IWMVUU/2501.html:text/html},
}
