\section{Rung 2: Intervention}

So far, there are several hypergraphs to model a probability distributions by a Bayesian Network.
We now want to understand the directed hyperedges as causal relationships between the variables, beyond encoding of conditional independencies (see \exaref{exa:patientTreatmentOutcome}).
To this end, we model the effects of interventions, which will distinguish between multiple Bayesian Networks modeling the same joint distribution.

\input{examples/patient_treatment_outcome}

Interventions on Bayesian Networks are modeled by the do-calculus \cite{pearl_causality_2009}, which we capture here based on do-variables.

\subsection{Do calculus}

We introduce the do-variables $\dovariableof{\catenumerator}$ taking values in $[\catdimof{\catenumerator}+1]$ for each variable $\catvariableof{\catenumerator}$ of dimension $\catdimof{\catenumerator}$, which model the effects of interventions.
The states are interpreted as
\begin{itemize}
    \item $\doindexof{\catenumerator}\in[\catdimof{\catenumerator}]$: An intervention setting $\catvariableof{\catenumerator}$ to the value $\doindexof{\catenumerator}$
    \item $\doindexof{\catenumerator}=\catdimof{\catenumerator}$: No intervention on $\catvariableof{\catenumerator}$
\end{itemize}

\begin{definition}
    The causally augmented conditional probability core is defined as
    \begin{align*}
        \condprobwrtof{\causalsymbol}{\catvariableof{\atomenumerator}}{\dovariableof{\catenumerator},\catvariableof{\parentsof{\catenumerator}}}
        =& \condprobof{\catvariableof{\catenumerator}}{\catvariableof{\parentsof{\catenumerator}}} \otimes \onehotmapofat{\catdimof{\catenumerator}}{\dovariableof{\catenumerator}} \\
        &+ \sum_{\doindexof{\catenumerator}\in[\catdimof{\catenumerator}]} \onehotmapofat{\doindexof{\catenumerator}}{\catvariableof{\catenumerator}} \otimes \onehotmapofat{\doindexof{\catenumerator}}{\dovariableof{\catenumerator}} \otimes \onesat{\catvariableof{\parentsof{\catenumerator}}}\, .
    \end{align*}
    The causally augmented Bayesian Network is the tensor network
    \begin{align*}
        \contractionof{
            \{\condprobwrtof{\causalsymbol}{\catvariableof{\catenumerator}}{\dovariableof{\catenumerator},\catvariableof{\parentsof{\catenumerator}}} \wcols \catenumeratorin\}
        }{\shortcatvariables,\dovariableof{[\catorder]}} \, .
    \end{align*}
\end{definition}

The Bayesian Networks investigated so far are retrieved by contractions with $\onehotmapofat{\catdimof{\catenumerator}}{\dovariableof{\catenumerator}}$.
This corresponds with the situation, where no interventions are performed on any variable.

\begin{lemma}
    For any Bayesian Network $\probwith$ on a directed acyclic hypergraph $\graph=([\catorder],\edges)$ we have
    \begin{align*}
        \probwith =
        \contractionof{
            \{\condprobwrtof{\causalsymbol}{\catvariableof{\catenumerator}}{\dovariableof{\catenumerator},\catvariableof{\parentsof{\catenumerator}}} \wcols \catenumeratorin\}
            \cup \{\onehotmapofat{\catdimof{\catenumerator}}{\dovariableof{\catenumerator}} \wcols \catenumeratorin \}
        }{\shortcatvariables} \, .
    \end{align*}
\end{lemma}
\begin{proof}
    By construction we have
    \begin{align*}
        \condprobwrtof{\causalsymbol}{\catvariableof{\atomenumerator}}{\dovariableof{\catenumerator}=\catdimof{\catenumerator},\catvariableof{\parentsof{\catenumerator}}}
        =& \condprobof{\catvariableof{\catenumerator}}{\catvariableof{\parentsof{\catenumerator}}}  \, .
    \end{align*}
    Performing this on each causally augmented conditional distribution retrieves thus the original Bayesian Network.
\end{proof}

\subsection{Intervention Queries}

In a Bayesian Network, when intervening on a variable $\catvariableof{\node}$, the corresponding conditional probability gets trivialized.
The probability tensor is then captured by
\begin{align*}
    \condprobat{\catvariableof{\secnodes}}{\doof{\indexedcatvariableof{\thirdnodes}}}
    %  \condprobat{\catvariableof{\secnodes}}{\doof{X}}
    = \contractionof{
        \{\condprobof{\catvariableof{\node}}{\catvariableof{\parentsof{\node}}} \,:\, \node\notin\thirdnodes \}
        \cup \{\frac{1}{\catdimof{\node}} \onesat{\catvariableof{\node},\catvariableof{\parentsof{\node}}} \,:\, \node\in\thirdnodes\}
        \cup \{\onehotmapofat{\catindexof{\node}}{\catvariableof{\node}} \,:\, \node\in\thirdnodes\}
    }{\catvariableof{\secnodes}} \, .
\end{align*}

Since $\frac{1}{\catdimof{\node}} \onesat{\catvariableof{\node},\catvariableof{\parentsof{\node}}}$ is directed with $\catvariableof{\parentsof{\node}}$ incoming and $\catvariableof{\node}$ outgoing, the partition function of the network stays $1$ and the normalization is captured by the contraction.

%    \subsection{Intervention Variables}
%
%    We modify conditional probability cores in Bayesian Networks to capture interventions, by introducing intervention variable
%
%    \begin{align*}
%        \hypercoreat{\catvariableof{\node},\catvariableof{\parentsof{\node}},\dovariableof{\node}}
%        = \condprobat{\catvariableof{\node}}{\catvariableof{\parentsof{\node}}} \otimes \onehotmapofat{0}{\dovariableof{\node}}
%        + \onesat{\catvariableof{\node},\catvariableof{\parentsof{\node}}} \otimes \tbasisat{\dovariableof{\node}}
%    \end{align*}

\subsection{Simplifications}

In general, when all variables are observable, intervention queries can be expressed by a collection of conditional queries (since any cpd of a Bayesian network is a conditional query, and we contract all except those with interventions on the head variables).
In realistic scenarios, however, not all variables are observable (for example, the smoking gene has been only assumed, but no observations have been made).
We are interested in situations, where intervention queries can be answered by conditional queries of observable variables.
We can proof them in the tensor network formalism based on network separations, which contribution to contractions are scalar multiplications, which therefore are dropped in normalizations.

An example for a simplification is given by the randomized controlled trial.

\input{examples/randomized_controlled_trial}

\subsubsection{Backdoor Criterion}

More general than in the randomized controlled trial we have to deal with confounding variables.
The Backdoor Criterion and the Frontdoor Criterion exploit mediator variables $\catvariableof{M}$, which are also observable and block certain causal paths to unobserved confounding variables $\catvariableof{U}$.

\begin{lemma}[Backdoor Criterion]
    When $\catvariableof{M}$ blocks any backdoor path from $\catvariableof{0}$ to $\catvariableof{1}$ and no node in $\catvariableof{M}$ is a descendant of $\catvariableof{0}$, then
    \begin{align*}
        \condprobwrtof{\causalsymbol}{\catvariableof{1}}{\dovariableof{0}=\catindexof{0}}
        = \contractionof{
            \condprobof{\catvariableof{1}}{\indexedcatvariableof{0},\catvariableof{M}},
            \probat{\catvariableof{M}}
        }{\catvariableof{1}} \, .
    \end{align*}
\end{lemma}
\begin{proof}
    By assumption, we can contract all variables beside $\catvariableof{[2]},\catvariableof{M}$ into cpds, and have a simplified causal model (see \figref{fig:backdoorCriterion}a).
    We have
    \begin{align*}
        \condprobwrtof{\causalsymbol}{\catvariableof{0}}{\dovariableof{0}=\catindexof{0},\catvariableof{M}}
        = \onehotmapofat{\catindexof{0}}{\catvariableof{0}} \otimes \onesat{\catvariableof{M}}
    \end{align*}
    and thus
    \begin{align*}
        \condprobwrtof{\causalsymbol}{\catvariableof{1}}{\dovariableof{0}=\catindexof{0}}
        = \contractionof{
            \condprobof{\catvariableof{1}}{\indexedcatvariableof{0},\catvariableof{M}},
            \probat{\catvariableof{M}}
        }{\catvariableof{1}} \, .
    \end{align*}
\end{proof}

\begin{figure}[t]
    \begin{center}
        \input{tikz_pics/backdoor_criterion}
    \end{center}
    \caption{Causal graph for the Backdoor Criterion.
    a) The mediator variable $\catvariableof{M}$ blocks any backdoor path from $\catvariableof{0}$ to $\catvariableof{1}$, potentially through a confounding variable $\catvariableof{U}$.
    b) The effect of the intervention on $\catvariableof{0}$ reduces the Bayesian network effectively to the shown subgraph.}
    \label{fig:backdoorCriterion}
\end{figure}


\begin{lemma}[Backdoor Criterion]
    When $\catvariableof{M}$ blocks any front door path from $\catvariableof{0}$ to $\catvariableof{1}$ and there is no confounder between $\catvariableof{0}$ and $\catvariableof{M}$, as well as between $\catvariableof{M}$ and $\catvariableof{1}$, then
    \begin{align*}
        \condprobwrtof{\causalsymbol}{\catvariableof{1}}{\dovariableof{0}=\catindexof{0}}
        = \contractionof{
            \condprobof{\catvariableof{M}}{\indexedcatvariableof{0}},
            \contractionof{\condprobof{\catvariableof{1}}{\catvariableof{M},\catvariableof{0}},\probat{\catvariableof{0}}}{\catvariableof{1},\catvariableof{M}}
%            \condprobof{\catvariableof{1}}{\catvariableof{M},\tildecatvariableof{0}},
%            \probat{\tildecatvariableof{0}}
        }{\catvariableof{1}} \, .
    \end{align*}
    Note that the inner contraction has $\catvariableof{0}$ as a closed variable.
\end{lemma}
\begin{proof}
    We show the claim for the situation in \figref{fig:frontdoorCriterion}
    \begin{align*}
        \condprobwrtof{\causalsymbol}{\catvariableof{1}}{\dovariableof{0}=\catindexof{0}}
        &= \contractionof{
            \condprobof{\catvariableof{M}}{\indexedcatvariableof{0}},
            \condprobof{\catvariableof{1}}{\catvariableof{M},\catvariableof{U}},
            \probat{\catvariableof{U}}
        }{\catvariableof{1}} \\
        &= \contractionof{
            \condprobof{\catvariableof{M}}{\indexedcatvariableof{0}},
            \contractionof{\condprobof{\catvariableof{1}}{\catvariableof{M},\catvariableof{U}},\probat{\catvariableof{U}}}{\catvariableof{1},\catvariableof{M}}
        }{\catvariableof{1}} \, .
    \end{align*}
    We note that
    \begin{align*}
        \contractionof{\condprobof{\catvariableof{1}}{\catvariableof{M},\catvariableof{U}},\probat{\catvariableof{U}}}{\catvariableof{1},\indexedcatvariableof{M}}
        &= \condprobwrtof{\causalsymbol}{\catvariableof{1}}{\dovariableof{M}=\catindexof{M}} \\
        &= \contractionof{\condprobof{\catvariableof{1}}{\catvariableof{M},\catvariableof{0}},\probat{\catvariableof{0}}}{\catvariableof{1},\indexedcatvariableof{M}}
    \end{align*}
    Here we used in the second equation that the variable $\catvariableof{0}$ blocks all backdoor paths from $\catvariableof{M}$ to $\catvariableof{1}$ (i.e. the backdoor criterion).
    Combining both equations proves the claim.
\end{proof}


\begin{figure}[t]
    \begin{center}
        \input{tikz_pics/frontdoor_criterion}
    \end{center}
    \caption{Causal graph for the Frontdoor Criterion.}
    \label{fig:frontdoorCriterion}
\end{figure}