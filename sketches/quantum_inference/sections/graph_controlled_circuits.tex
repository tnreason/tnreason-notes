\section{Graph-Controlled circuits}

Let us now introduce the most generic circuit construction schemes used in this work.
To this end, we exploit the definition of uniformly controlled unitaries (see \cite{mottonen_transformation_2005}), and study their alignment along directed acyclic hypergraphs.

\begin{definition}[Graph-Controlled Circuit]
    Let $\graph=(\nodes,\edges)$ be a directed acyclic hypergraph, where each hyperedge has exactly one outgoing node and all nodes appear exactly once as outgoing nodes of an hyperedge.
    Then a by $\graph$ controlled circuit is a decoration of the edges $\edge=(\incomingnodes,\{\node\})\in\edges$ by uniformly controlled unitaries
    \begin{align*}
        \contunitaryofat{\edge}{\catvariableof{\node,\insymbol},\catvariableof{\node,\outsymbol},\catvariableof{\incomingnodes,\outsymbol}} \, .
    \end{align*}
\end{definition}

%%
\begin{example}[Generic State Representation]\label{exa:genericControlCircuit}
    In \cite{mottonen_transformation_2005} a preparation scheme for arbitrary states with real and positive amplitudes by graph-controlled circuits is presented.
    Therein, the hypergraph $\graph=(\nodes,\edges)$ is constructed as follows:
    \begin{itemize}
        \item Nodes $\nodes={[\catorder]}$
        \item Edges $\edges=\left\{([\catenumerator],\{\catenumerator\})\wcols\catenumeratorin\right\}$
    \end{itemize}
\end{example}

This is closely connected to the chain decomposition of probability distributions, and their construction
In \cite{low_quantum_2014} Bayesian Networks are prepared by graph-controlled circuits.
When in the graph $\graph$ each node appears at most once as outgoing node, it is also the hypergraph to a family of Bayesian Networks.
The measurement distributions of a state prepared by a $\graph$-controlled Circuit acting on disentangled initial states are exactly the Bayesian Networks with respect to $\graph$.

\begin{theorem}
    \label{the:graphControlledPreparesBN}
    Let $\graph$ be a directed acyclic hypergraph, such that node appears at most once as an outgoing node.
    The measurement distributions of the by $\graph$ controlled circuits acting on disentangled initial states are equal to the Bayesian Networks on $\graph$.
\end{theorem}

\begin{lemma}
    Let $\graph$ be a directed acyclic hypergraph, such that node appears at most once as an outgoing node.
    Then any Bayesian network on $\graph$ can be prepared by a $\graph$-controlled circuit with activation circuits of the conditional probability tensors.
\end{lemma}
\begin{proof}
    Let $\probwith$ be a Bayesian network on the graph $\graph$.
    Enumerate the nodes $\nodes$ of the $\graph$ by $[\atomorder]$, such that for each $\catenumeratorin$ we have $\parentsof{\catenumerator}\subset[\catenumerator]$.
    Then define a $\graph$-controlled circuit, by choosing for each $\catenumeratorin$ controlled unitaries which satisfy
    \begin{align*}
        \contunitaryofat{\catenumerator}{\catvariableof{\catenumerator,\insymbol}=0,\catvariableof{\node,\outsymbol},\catvariableof{\parentsof{\catenumerator},\outsymbol}}
        =\sqrt{\condprobof{\catvariableof{\catenumerator}}{\catvariableof{\parentsof{\catenumerator}}}} \, .
    \end{align*}
    Here we specified only the action of the controlled unitary on the basis vector $\onehotmapofat{0}{\catvariableof{\catenumerator}}$, the action on $\onehotmapofat{1}{\catvariableof{\catenumerator}}$ can be chosen by an arbitrary orthogonal unit vector. % Maybe link here the activation circuit scheme, which is already used?
    For more explicit construction, see the \activationCircuits{} in \secref{sec:functionEncoding}.
    Any such defined $\graph$-controlled circuit acting on the initial state $\bigotimes_{\catenumeratorin}\onehotmapofat{0}{\catvariableof{\catenumerator}}$ prepares a quantum state $\qstatewith$ with measurement distribution
    \begin{align*}
        \absof{\qstate}^2\left[\shortcatvariables\right] \, .
    \end{align*}
    Given arbitrary $\shortcatindicesin$ we have
    \begin{align*}
        \absof{\qstate}^2\left[\indexedshortcatvariables\right]
        = \prod_{\catenumeratorin} \condprobof{\indexedcatvariableof{\catenumerator}}{\indexedcatvariableof{\parentsof{\catenumerator}}}
        = \probat{\indexedshortcatvariables} \, .
    \end{align*}
    Here we used in the last equation, that $\probwith$ is a Bayesian network.
    Since the equivalence holds for any coordinate, this establishes the equivalence of the measurement distribution of $\qstatewith$ and $\probwith$.
\end{proof}

The contrary is true, also when nodes appear multiple times as outgoing nodes.

\begin{lemma}
    Let $(\graph,\contunitary)$ be a $\graph$-controlled circuit acting on a disentangled initial state and $\probat{\nodevariables}$ the corresponding measurement distribution.
    Then we have for each $\node\in\nodes$ the conditional independence
    \begin{align*}
        \condindependent{\catvariableof{\node}}{\catvariableof{\nondescendantsof{\node}}}{\catvariableof{\parentsof{\node}}} \, .
    \end{align*}
\end{lemma}
\begin{proof}
    We choose to a given $\node\in\nodes$ an enumeration $[\catorder]$ of the nodes, such that for each $\catenumeratorin$ we have $\parentsof{\catenumerator}\subset[\catenumerator]$ and for the enumerator $\seccatenumerator$ of $\node$ we further have $\nondescendantsof{\seccatenumerator}\subset[\seccatenumerator]$.
    Let $\probwith$ be the measurement distribution of the $\graph$-controlled circuit acting on a disentangled initial state $\bigotimes_{\catenumeratorin}\qstateofat{\catenumerator}{\catvariableof{\catenumerator}}$ and choose arbitrary $\catindexof{[\catenumerator]}$.
    We then have
    \begin{align*}
        \probat{\catvariableof{\seccatenumerator},\indexedcatvariableof{[\catenumerator]}}
        &= \contractionof{\left(\bigcup_{\catenumeratorin}\{\contunitaryof{\catenumerator},\contunitaryof{\catenumerator,\dagger},\qstateof{\catenumerator},\qstateof{\catenumerator,*}\right)\}
            \cup \left(\bigcup_{\catenumerator\in[\seccatenumerator]} \onehotmapofat{\catindexof{\catenumerator}}{\catvariableof{\catenumerator,\outsymbol}}\right)
        }{
            \catvariableof{\seccatenumerator}
        } \\
        &= \contractionof{\bigcup_{\catenumerator\in[\seccatenumerator]}\{\contunitaryof{\catenumerator},\contunitaryof{\catenumerator,\dagger},\qstateof{\catenumerator},\qstateof{\catenumerator,*},\onehotmapofat{\catindexof{\catenumerator}}{\catvariableof{\catenumerator,\outsymbol}}\}}{
            \catvariableof{\seccatenumerator}
        } \\
        & = \absof{\contractionof{\contunitaryofat{\seccatenumerator}{\catvariableof{\seccatenumerator,\insymbol},\catvariableof{\seccatenumerator,\outsymbol}},\indexedcatvariableof{\parentsof{\seccatenumerator},\outsymbol}}{\catvariableof{\seccatenumerator,\outsymbol}}}^2 \\
        & \quad \quad \cdot \prod_{\catenumerator\in[\seccatenumerator]}
        \left(\contraction{\qstateofat{\catenumerator}{\catvariableof{\catenumerator,\insymbol}},\contunitaryofat{\catenumerator}{\catvariableof{\catenumerator,\insymbol},\catvariableof{\catenumerator,\outsymbol},\indexedcatvariableof{\parentsof{\catenumerator},\outsymbol}}}\right)^2
        %\contraction{\qstateof{\catenumerator,*},\onehotmapofat{\catindexof{\catenumerator}}{\catvariableof{\catenumerator}}}{} \, .
    \end{align*}
    Here we used in the second equation the unitarity of the controlled unitaries to $\catenumerator\notin[\seccatenumerator]$.
    Since the indices $\catindexof{[\seccatenumerator]/\parentsof{\seccatenumerator}} = \catindexof{\nondescendantsof{\seccatenumerator}}$ appear only in the constant term, we conclude
    \begin{align*}
        \condprobat{\catvariableof{\seccatenumerator}}{\catvariableof{[\catenumerator]}} = \condprobat{\catvariableof{\seccatenumerator}}{\catvariableof{\parentsof{\seccatenumerator}}} \otimes \onesat{\catvariableof{\nondescendantsof{\seccatenumerator}}}\, ,
    \end{align*}
    which establishes the conditional independence $\condindependent{\catvariableof{\node}}{\catvariableof{\nondescendantsof{\node}}}{\catvariableof{\parentsof{\node}}}$.
\end{proof}

\begin{proof}[Proof of \theref{the:graphControlledPreparesBN}]
    The theorem follows directly from the two lemmas, using that Bayesian Networks are characterized by the conditional independence of each variable to its non-descendants given its parents.
\end{proof}

\begin{example}[Chain decomposition]
    The hypergraph in \exaref{exa:genericControlCircuit} corresponds with a family of Bayesian Networks subsuming any probability distribution.
    This can be verified based on the chain decomposition of a generic distribution.
\end{example}

%% Phase representation
Another question is, whether each quantum state, which measurement distribution is a Bayesian Network can be prepared by a $\graph$-controlled circuit.
This is not always the case, since the phase tensor does not influence the measurement distribution.
Any phase tensor, of a by $\graph$-controlled circuit prepared state has however a decomposition
\begin{align*}
    \phasecoreat{\shortcatvariables}
    = \sum_{\catenumeratorin} \phasecoreofat{\catenumerator}{\catvariableof{\catenumerator},\catvariableof{\parentsof{\catenumerator}}} \otimes \onesat{\catvariableof{[\catorder]/\{\{\catenumerator\}\cup\parentsof{\catenumerator}\}}} \, ,
\end{align*}
where the phase cores $\phasecoreof{\catenumerator}$ can be read of the controlled unitaries.
When there are phase cores which do not have such a decomposition, the corresponding states are not representable.
\cite{mottonen_transformation_2005} shows, that when the graph is chosen as in \exaref{exa:genericControlCircuit}, then also the phases can be represented.


%\section{Function Encoding Schemes}\label{sec:functionEncoding}

\subsection{\ActivationCircuit{}}

We now investigate quantum pendants to the function encoding schemes used in \tnreason{}{}.
All the schemes are graph-controlled circuits.

\begin{itemize}
    \item Pendant for Coordinate Encoding in \tnreason{}: Amplitude Encoding, storing the function value in the amplitude of an ancilla qubit.
    This is realized by an \textbf{\ActivationCircuit{}} acting on an ancilla qubit in the ground state.
    \item Pendant for Basis Encoding in \tnreason{}: \textbf{\ComputationCircuit{}}, with composition by contraction property.
    Applied on the ground state, the \computationCircuit{} generates the basis encoding quantum state, which is parallel to the basis encoding.
\end{itemize}

Both are defined using controlled single qubit gates (see Sections 4.2-3 in [Nielsen, Chuang]) with ancilla qubits being the target qubits. % where the incoming qubit variable is $\avariableof{\insymbol}$ and the outgoing $\avariableof{\outsymbol}$.


\ActivationCircuits{} are uniformly controlled unitaries (see \cite{mottonen_transformation_2005}), where the rotation axis is chosen as the $y$-axes of the Bloch sphere, and the angles are computed by the function $h(\cdot)$.
%\red{Introduce rotation encodings based on activation circuit action, hint at a sampling scheme of probability distributions.}

%% Angle preparing
We define the angle preparing function on $p\in[0,1]$ by
\begin{align*}
    h(p) = 2 \cdot \mathrm{cos}^{-1}\left(\sqrt{1-p}\right) \, .
\end{align*}
For any $p\in[0,1]$ we then have
\begin{align*}
    \contractionof{\onehotmapofat{0}{\avariableof{\insymbol}},\yrotationofat{h(p)}{\avariableof{\insymbol},\avariableof{\outsymbol}}}{\avariableof{\outsymbol}}
    = \begin{bmatrix}
          \sqrt{1-p} \\
          \sqrt{p}
    \end{bmatrix} \, .
\end{align*}

\begin{definition}[\ActivationCircuit{}]
    Given a function
    \begin{align*}
        \exformula : \bigtimes_{\selindexin} [2] \rightarrow [0,1]
    \end{align*}
    its \activationCircuit{} is the uniformly controlled unitary
    $\qcaencodingofat{\hypercore}{\avariableof{\insymbol},\avariableof{\outsymbol},\headvariables}$ defined as
    \begin{align*} %% Could ease the definition by coordinates
        \qcaencodingofat{\hypercore}{\avariableof{\insymbol},\avariableof{\outsymbol},\headvariables}
        = \sum_{\shortheadindices} \onehotmapofat{\shortheadindices}{\headvariables}
        %\otimes \onehotmapofat{\shortheadindices}{\headvariableof{\insymbol,[\seldim]}}
        \otimes \yrotationofat{h(\exformulaat{\shortheadindices})}{\avariableof{\insymbol},\avariableof{\outsymbol}} \, .
    \end{align*}
\end{definition}

%% Drop the in and out
We will ease our notation by dropping the $\insymbol$ and $\outsymbol$ labels to the control variables.
This amounts to understanding the Dirac delta tensors in \activationCircuits{} as hyperedges.
Along that picture the quantum circuit is a tensor network on hyperedges instead of edges.


%% As a graph-controlled circuit
Each activation circuit is a graph-controlled circuit, where the corresponding hypergraph consists in $\nodes=\headvariables\cup\{\avariable\}$ and a single edge $\edges=(\headvariables,\{\avariable\})$.

When we have a probability tensor, its \activationCircuit{} be prepared, since all values are in $[0,1]$.
Note that for rejection sampling, only the quotients of the values are important, we can therefore scale the value by a scalar such that the mode is $1$.

%% Rescaling tensors with larger coordinates
Tensors $\hypercoreat{\headvariables}$ with non-negative coordinates can be encoded after dividing them by their maximum, that is the \activationCircuit{} of the function
\begin{align*}
    \exformulaat{\shortheadindices} = \frac{\hypercoreat{\headvariables=\shortheadindices}}{\max_{\secheadindexof{[\seldim]}} \hypercoreat{\headvariables=\secheadindexof{[\seldim]}}}
\end{align*}
When the maximum of the tensor is not known, it can be replaced by an upper bound (reducing the acceptance rate of the rejection sampling).

%% Generic Tensors with complex amplitudes: Require besides rescaling more general unitaries.

\subsubsection{Encoding of conditional distributions}

Following the schemes in \cite{low_quantum_2014}, we can prepare the acyclic networks of directed and non-negative tensors by a sequence of controlled rotations.
Directed and non-negative tensors correspond with conditional probability distributions and their acyclic networks are Bayesian Networks.
We prepare them by \activationCircuit{}s of functions (see \figref{fig:cpdEncoding})
\begin{align*}
    \catindexof{\parentsof{\catenumerator}} \rightarrow \condprobat{\catvariableof{\catenumerator}=1}{\indexedcatvariableof{\parentsof{\catenumerator}}} \, .
\end{align*}

\subsubsection{Encoding of Bayesian Networks}

We revisit the correspondence of Bayesian Networks with graph-controlled circuits, by showing that any Bayesian Network can be prepared by \activationCircuits{} of the conditional probability distributions.
Bayesian Networks can be prepared as quantum circuits, where each conditional probability distribution is prepared by an \activationCircuit{}.

\begin{theorem}[Low et al.]
    Any Bayesian Network of variables $\shortcatvariables$, where the enumeration by $[\atomorder]$ respects the partial order by child-parent relations, can be prepared as a quantum circuit by concatenating the \activationCircuit{}s
    \begin{align*}
        \qcaencodingofat{
            \condprobat{\catvariableof{\catenumerator}=1}{\catvariableof{\parentsof{\catenumerator}}}
        }{\catvariableof{\catenumerator,\insymbol},\catvariableof{\catenumerator},\catvariableof{\parentsof{\catenumerator}},\catvariableof{\parentsof{\catenumerator}}}
    \end{align*}
    for $\atomenumeratorin$ and acting on the initial state $\bigotimes_{\atomenumeratorin}\onehotmapofat{0}{\catvariableof{\catenumerator,\insymbol}}$ .
\end{theorem}


%To this end, one iterates over the states of the incoming variables, and performs a controlled rotation on the outgoing variable, where the angle is given by the value of the tensor at the incoming state.
%This generalizes the basis encoding scheme, which demands boolean tensors.

\begin{figure}
    \begin{center}
        \input{./tikz_pics/directed_to_circuit.tex}
    \end{center}
    \caption{
        Representation of directed and positive tensor by a controlled rotation.
        a) Conditional probability tensor $\condprobat{\catvariableof{\catenumerator}}{\catvariableof{\parentsof{\catenumerator}}}$ being a tensor in a Bayesian Network.
        b) Circuit Encoding as a controlled rotation, which is the \ActivationCircuit{} of the tensor $\condprobat{\catvariableof{\catenumerator}=1}{\catvariableof{\parentsof{\catenumerator}}}$.
    }\label{fig:cpdEncoding}
\end{figure}

%\subsubsection{Encoding of independent distributions}
%
%An extremal case of Bayesian networks is those where all variables are mutually independent.
